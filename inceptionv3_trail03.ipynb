{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNS82j/3yGBEKHR1VQ9SBOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tricksterwink/btp/blob/main/inceptionv3_trail03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DFoNYaQBmPO",
        "outputId": "68cd4416-1847-4f09-9a29-e579f3727b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "gZfSkX3SBqk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training and validation data directories\n",
        "train_dir = '/content/drive/MyDrive/Sample Rice/Train'"
      ],
      "metadata": {
        "id": "ZrLGvIjbB7BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an ImageDataGenerator for preprocessing with augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "q-weSQmcB9sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the datagen to generate augmented training data\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(512, 512),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9b9NcfcCABo",
        "outputId": "f2b8aa3a-646d-4147-c145-c0bd0d7d6ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 784 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a separate generator for validation data without augmentation\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(512, 512),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zsX3TidCCSW",
        "outputId": "9b6587d4-e423-45ab-e1cb-56bd9e771338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 196 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom learning rate schedule function\n",
        "def learning_rate_schedule(epoch):\n",
        "    initial_learning_rate = 0.0001\n",
        "    decay = 0.9\n",
        "    min_learning_rate = 1e-7\n",
        "\n",
        "    new_learning_rate = initial_learning_rate * (decay ** epoch)\n",
        "    new_learning_rate = max(new_learning_rate, min_learning_rate)\n",
        "\n",
        "    return new_learning_rate"
      ],
      "metadata": {
        "id": "vuKrk8ONCEj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience = 2,\n",
        "    restore_best_weights = True\n",
        ")"
      ],
      "metadata": {
        "id": "XLNTHGuQCGyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet50 without the top classification layers\n",
        "pretrained_model = tf.keras.applications.InceptionV3(include_top = False,\n",
        "                   input_shape = (512, 512, 3),\n",
        "                   pooling = 'avg',\n",
        "                   weights = 'imagenet')\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAqQIOMGCJKi",
        "outputId": "783df744-d26c-4acc-958b-a537bd90658b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your custom classification model\n",
        "inceptionv3_model = Sequential()\n",
        "inceptionv3_model.add(pretrained_model)\n",
        "inceptionv3_model.add(Flatten())\n",
        "\n",
        "inceptionv3_model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "inceptionv3_model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))"
      ],
      "metadata": {
        "id": "-rSwvrVuCM2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output layer\n",
        "inceptionv3_model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "dBuypsiOCO6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inceptionv3_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK6EkStUCQiX",
        "outputId": "08c9f18f-d636-40ae-eb1c-570a53c25e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 2048)              21802784  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22343906 (85.24 MB)\n",
            "Trainable params: 541122 (2.06 MB)\n",
            "Non-trainable params: 21802784 (83.17 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "inceptionv3_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sqCtOgBECS7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a LearningRateScheduler callback during model training\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate_schedule)\n",
        "\n",
        "epochs = 10\n",
        "history = inceptionv3_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[lr_scheduler, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgsVgPSXBxO4",
        "outputId": "20c60be8-5dd9-4161-bfd2-ad882fbc87c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 1287s 96s/step - loss: 1.1699 - accuracy: 0.6671 - val_loss: 1.0650 - val_accuracy: 0.8878 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 1109s 84s/step - loss: 0.9974 - accuracy: 0.9503 - val_loss: 0.9324 - val_accuracy: 0.9337 - lr: 9.0000e-05\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 1106s 84s/step - loss: 0.8881 - accuracy: 0.9719 - val_loss: 0.8402 - val_accuracy: 0.9541 - lr: 8.1000e-05\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 1072s 81s/step - loss: 0.8127 - accuracy: 0.9681 - val_loss: 0.7816 - val_accuracy: 0.9694 - lr: 7.2900e-05\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 1125s 86s/step - loss: 0.7490 - accuracy: 0.9821 - val_loss: 0.7221 - val_accuracy: 0.9796 - lr: 6.5610e-05\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 1111s 91s/step - loss: 0.7097 - accuracy: 0.9758 - val_loss: 0.7001 - val_accuracy: 0.9694 - lr: 5.9049e-05\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 1107s 84s/step - loss: 0.6854 - accuracy: 0.9745 - val_loss: 0.6608 - val_accuracy: 0.9898 - lr: 5.3144e-05\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 1065s 81s/step - loss: 0.6560 - accuracy: 0.9949 - val_loss: 0.6437 - val_accuracy: 0.9898 - lr: 4.7830e-05\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 1100s 84s/step - loss: 0.6305 - accuracy: 0.9860 - val_loss: 0.6224 - val_accuracy: 0.9898 - lr: 4.3047e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "inceptionv3_model.save('/content/drive/MyDrive/Sample Rice/inceptionv3_model_trail03.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX3MKTL9C89W",
        "outputId": "9176d776-486c-460e-f682-fbdced4e4121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load saved model\n",
        "from keras.models import load_model\n",
        "\n",
        "loaded_model = load_model('/content/drive/MyDrive/Sample Rice/inceptionv3_model_trail03.h5')"
      ],
      "metadata": {
        "id": "0m-L0y6Xq8bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_path = '//content/drive/MyDrive/Sample Rice/Test/1121RAW/112100101.JPG'\n",
        "img = image.load_img(img_path, target_size=(512, 512))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x / 255.0\n",
        "\n",
        "# Make prediction\n",
        "predictions = loaded_model.predict(x)\n",
        "\n",
        "# The predictions will be a probability distribution over the classes\n",
        "# using argmax to get the predicted class\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCpXtgKUrcV-",
        "outputId": "8b99402c-21a2-4061-b4b7-acb6e808597f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the image\n",
        "img_path = '/content/drive/MyDrive/Sample Rice/Test/PR14RAW/PR14RAW00101.JPG'\n",
        "img = image.load_img(img_path, target_size=(512, 512))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x / 255.0\n",
        "\n",
        "# Make prediction\n",
        "predictions = loaded_model.predict(x)\n",
        "\n",
        "# The predictions will be a probability distribution over the classes\n",
        "# using argmax to get the predicted class\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhj1enqrsGVf",
        "outputId": "c829bcab-0ca7-4980-b8cf-d0f5bbd88e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 680ms/step\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory containing the test images\n",
        "test_dir = '/content/drive/MyDrive/Sample Rice/Test'\n",
        "\n",
        "# Get the list of subdirectories (which are the classes)\n",
        "classes = os.listdir(test_dir)\n",
        "\n",
        "for class_name in classes:\n",
        "    class_dir = os.path.join(test_dir, class_name)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = image.load_img(img_path, target_size=(512, 512))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = x / 255.0\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = loaded_model.predict(x)\n",
        "\n",
        "        # If you have binary classification, you can use argmax to get the predicted class\n",
        "        predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "        print(f\"Image '{img_name}' in class '{class_name}' is predicted as class {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srr1SUQtsZyi",
        "outputId": "d9c10c1f-d876-4778-a472-01ab079f6a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 934ms/step\n",
            "Image '112100101.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 651ms/step\n",
            "Image '112100102.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 652ms/step\n",
            "Image '112100103.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 659ms/step\n",
            "Image '112100104.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 662ms/step\n",
            "Image '112100105.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image '112100106.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image '112100107.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 669ms/step\n",
            "Image '112100108.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 660ms/step\n",
            "Image '112100109.JPG' in class '1121RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 662ms/step\n",
            "Image '112100110.JPG' in class '1121RAW' is predicted as class 0\n",
            "1/1 [==============================] - 1s 670ms/step\n",
            "Image 'PR14RAW00108.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 665ms/step\n",
            "Image 'PR14RAW00102.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 658ms/step\n",
            "Image 'PR14RAW00103.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image 'PR14RAW00105.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Image 'PR14RAW00104.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 666ms/step\n",
            "Image 'PR14RAW00101.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 666ms/step\n",
            "Image 'PR14RAW00109.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 694ms/step\n",
            "Image 'PR14RAW00110.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 678ms/step\n",
            "Image 'PR14RAW00107.JPG' in class 'PR14RAW' is predicted as class 1\n",
            "1/1 [==============================] - 1s 650ms/step\n",
            "Image 'PR14RAW00106.JPG' in class 'PR14RAW' is predicted as class 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory containing the test images\n",
        "test_dir = '/content/drive/MyDrive/Sample Rice/Test'\n",
        "\n",
        "# Get the list of subdirectories (which are the classes)\n",
        "classes = os.listdir(test_dir)\n",
        "\n",
        "# Initialize variables to keep track of total and correct predictions\n",
        "total_predictions = 0\n",
        "correct_predictions = 0\n",
        "\n",
        "for class_name in classes:\n",
        "    class_dir = os.path.join(test_dir, class_name)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = image.load_img(img_path, target_size=(512, 512))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = x / 255.0\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = loaded_model.predict(x)\n",
        "        predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "        if predicted_class == classes.index(class_name):  # Assuming classes are sorted alphabetically\n",
        "            correct_predictions += 1\n",
        "\n",
        "        total_predictions += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "print(f\"Total predictions: {total_predictions}\")\n",
        "print(f\"Correct predictions: {correct_predictions}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFx8lllTumDh",
        "outputId": "5ec7c7b4-79c4-4cba-eb91-cd55cd78994e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 677ms/step\n",
            "1/1 [==============================] - 1s 673ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 659ms/step\n",
            "1/1 [==============================] - 1s 668ms/step\n",
            "1/1 [==============================] - 1s 657ms/step\n",
            "1/1 [==============================] - 1s 645ms/step\n",
            "1/1 [==============================] - 1s 672ms/step\n",
            "1/1 [==============================] - 1s 680ms/step\n",
            "1/1 [==============================] - 1s 668ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 668ms/step\n",
            "1/1 [==============================] - 1s 659ms/step\n",
            "1/1 [==============================] - 1s 678ms/step\n",
            "1/1 [==============================] - 1s 669ms/step\n",
            "Total predictions: 20\n",
            "Correct predictions: 19\n",
            "Accuracy: 95.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HJEZrTxju-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}